[RTP-LLM 大模型推理引擎P-D分离 思考篇 - 知乎](https://zhuanlan.zhihu.com/p/19796399275)

# 摘要
### 推理过程-prefill-decode。

prefill，输出prompt，输出第一个output token，生成kv cache。

decode，每轮生成一个output token，附加到kv cache。

Pefill 阶段通常是计算密集型的，Decode 阶段通常是显存带宽瓶颈。

（这里太宏观了，比如decoder模型，每个模型有n个transformer block，那么每个block使用的kv cache都是不同的（输入不同、参数不同），而且层与层之间是流水线的关系（所以，上一层kv cache能在完成本层的计算后，先传输到decode节点，而不需要考虑下一层的问题））


### 调度策略
continuous batch的调度，会在每一次执行prefill或decode时，进行调度，删除已经完成的请求。**并且将能满足显存需求的 Prefill 请求和 Decode 请求凑批执行。（我看到的文章是先进行prefill，尽可能提升decode的batch，再进行decode，这里的意思应该是chunked prefill？或者不chunked，但是将prefill 与decode拼接。）**
Prefill 阶段运行时间较长，此时 Decode 阶段的时延受到较大影响（作者这里的意思是decode的TTFT吗？）。**最终体现为只要请求出现了 P-D 请求凑批执行，那么请求的平均时延和 P99 时延就会出现巨大波动，这个问题在线上场景时刻存在。**

当然也有其他调度策略：

1. Prefill 优先策略，Prefill-Decode 请求不允许凑批，那么对 Decode 请求的影响更大（标准的continuous batch，decode请求优先级低，会插入prefill的阶段，dedode输出的速度肯定是更慢的，但是减少了总的请求的耗时？）。
2. Decode 优先策略，Prefill-Decode 请求不允许凑批，会使得 GPU 利用效率降低（先decode，那么ttft就很差，没有decode才进行prefill，这个逻辑似乎更差）。
3. Chunked Prefill [1] 技术将 Prefill 的请求拆成多个部分多轮执行，在每轮中和 Decode 请求凑批执行，可以提高 Decode 请求的交互性能，但是它的总时延还是会受到 Prefill 请求的影响。并且因为 Prefill 请求仍然长时间占用显存，导致 Decode 请求的并发受到限制。

好像并没有完美的解决方案，既然不能同时满足两个阶段的需求，干脆直接将它们拆分得了。

### 预计的好处
**我们预计 [P-D 分离]可以带来一些好处：
- 它们可以选择**不同的机型**，Prefill 采用高算力的 GPU，Decode 采用大显存的 GPU。
- 它们可以选择**不同的量化方式和凑批大小**。这样就可以同时优化首字时间（TTFT）和 Time Between Tokens（TBT）。（机器相同，也可以根据prefill和decode的特点，**分别对prefill使用小batch和decode使用大batch**）
- **最重要的是不同请求的 Prefill 阶段的执行不再会影响 Decode 阶段，使得请求总时延和 P99 时延稳定。**（为什么总时延和 P99 时延会有影响？？？）

# 通信
数据传输和控制信息传输。

数据传输部分使用 TCP / RDMA，TCP 使用在无 RDMA 卡的简单环境。

控制信息的传输主要是为了控制整个流程运转，以及配合 RDMA 的单边操作。

### **数据传输**
大概就是TCP是基于CPU的且路径长，RDMA路径短

# 收益
 P-D 分离是否能降本

首先 P-D 分离带来了凑批策略的变化，也同时使得 P-D 的资源分配（实例个数，GPU卡型）不再一致。这就为将种类纷繁的卡型纳入统一管理从而减少碎片带来了基础条件。

当然，在此基础上我们希望更进一步的减少显存占用大小，降低显存的无效占用时间。

目标：减少显存占用的大小和无效占用的时间。

### 凑batch的策略（P节点与D节点分离）
Prefill-Decode 融合架构，由于 Prefill 的计算瓶颈，所以 Prefill 的 Batch Size 不会很大，这样就导致 Decode 阶段的 Batch Size 也不一定能上来。

但是 Decode 其实是更适合大批次运行的，在达到计算瓶颈之前，随着 Batch Size 的增大，Decode 时延的增长是比较缓慢的。

在 P-D 分离之后，Prefill 本身的 Batch Size 仍然不会很大。为了充分发挥 Decode 的能力，**我们应该配置更多的 Prefill，减少 Decode 实例个数，使得 Decode 能进行大 Batch 推理**。（dense模型的特点决定了，prefill与decode的对应关系是n:1的）

### 资源分配（卡型选择，计算力强和显存大的）
P-D 分离之后，应该各自如何配置 CPU 和 GPU ？

首先，相比较 P-D 融合架构，CPU 消耗的会更多，因为增加了多次 GPRC 交互，并且 Decode 的 Response 需要流式的返回给 Prefill。而我们使用的 GRPC C++ 版本，可以使用多线程从而利用多 CPU 核的能力。所以它们只需要有充分的 CPU 即可。


**GPU 方面

Prefill 非常消耗算力，并且在 Prefill **传输 KVCache 给 Decode 之后，显存不需要占用，那么可以用来服务其他请求**。所以 Prefill 一般是先达到计算瓶颈，而不是显存容量瓶颈，**所以 Prefill 应该选择计算能力强的卡型**。

从凑批策略章节可知 Decode 的实例个数会变少，所以并发执行的请求比较多，并且 Decode 的总时间一般比较长，所以显存有效占用时间比较长，**所以 Decode 应该着重选择显存大的卡型**。

### 成本管理(管理不同的卡)

从 P-D 分离的资源分配章节，我们从它们的特性出发，已经推导出 P-D 的机型可能不一致。但现实是，我们有什么机型呢。现实中，我们有不同类型不同数量的 GPU，AMD，ARM 等计算设备。


显存小的，我们可以组成更大的 TP，计算能力差的，我们可以使用更多实例。并且对于 Prefill / Decode 内部，也可能是不同的卡型。例如说，Decode 有多组不同配置，不同 TP，不同卡型的集群。**充分的将一些小卡，一些数量不足的卡，组织起来，形成大容量集群**。

  

那 P-D 分离架构能降低成本吗？

例如说在 P-D 融合架构下，是 20 个节点承担 10 QPS 的流量。在 P-D 分离架构下，至少一个 Decode 节点，最好有两个，保证 Decode 不会同时挂掉，那么还剩下 18 个 Prefill 节点，此时它还能承担 10 QPS 的流量吗。**我们认为考察一个服务的质量，不是单独考察时延，也不是单独考察吞吐。而是考察在一定时延（包括平均时延和 P99 时延）限值范围下的吞吐，或者是考虑相同吞吐下的时延**。

我们认为 P-D 分离可以降低时延，那么就可以使用更少的实例个数来承担和之前一样的 QPS，这样就可以节省成本。更进一步的，我们可以把业务方的资源额度下的边边角角的一些零碎的卡型纳入管理范围。


### 量化（PD节点使用不同的量化方式）
总结：

PD融合时，很难选择一个好的量化方案，W4A16 有更好的 Decode 性能，但会造成很长的 TTFT（甚至大于FP16）；W8A8 确实可以更快完成 Prefill，但时延却不一定短于 W4A16，更长的时延也不利于更大的吞吐。在单部署只保存一份模型权重的情况下，PD两个阶段不能使用不同的量化方案。

**基于 P-D 分离的方案，我们可以自由地在 Prefill 机器部署 FP16 / W8A8 的模型文件，来获得相对不错的 Prefill 性能；而 Decode 机器则可以自由地选择 W4A16 / W4A8 的方案，来获得整体的更优性能**。

原文：

我们想到量化可以使得显存占用变少，从而可以**提高请求并发度**。

我们已经支持的量化类型包括 W8A16、W4A16 和 W8A8（INT8 和 FP8）。

在这里，如果计算类型维持 FP16，那么量化仅在短 Prompt 时有助于加速 Load Weight；而计算类型如果对应的改成 INT8/FP8，则可以利用 INT8/FP8 的算力（通常是 FP16 的两倍）。若不考虑模型效果，假设各种量化方案下模型都有足够优秀的表现能力，我们当然希望 Prefill 能更充分的利用算力，Decode 可以用上更充足的带宽。

  

在过去的部署里，我们很难协调一个问题，当用户的输入和输出都比较长时，我们应该给用户推荐怎么样的量化方案？W4A16 有更好的 Decode 性能，但会造成很长的 TTFT（甚至大于FP16）；W8A8 确实可以更快完成 Prefill，但时延却不一定短于 W4A16，更长的时延也不利于更大的吞吐。有没有可能两个阶段使用不同的量化方案呢？在单部署只保存一份模型权重的情况下，这是做不到的。

所幸 P-D 分离终于为我们提供了 Prefill 和 Decode 分开部署的方案。**基于 P-D 分离的方案，我们可以自由地在 Prefill 机器部署 FP16 / W8A8 的模型文件，来获得相对不错的 Prefill 性能；而 Decode 机器则可以自由地选择 W4A16 / W4A8 的方案，来获得整体的更优性能**。这是 P-D 分离在部署上的额外收益，为部署模型精度提供了更多的选择。

### 显存有效占用（通过调度，减少无效占用显存的时间）

我们不但希望减少显存占用，并且希望能更有效的占用显存：

- 在 Prefill 的请求排队结束开始执行时，此时 Decode 开始申请显存资源，可以减少排队期间的无效显存占用。
- 在 Prefill **发送完毕显存**时，可以将显存立刻释放给其他请求使用。
- 在 Decode 请求结束时，Decode 才回传计算产出的 KVCache 给 Prefill，而不是从 Decode 的第一个输出 Token 开始就一边生成一边传输，减少 Prefill 的显存占用时间。当然这个策略，可能会使得传输时延的影响被放大，所以可以提前发送，在计算和传输的 Overlap 与显存占用时间之间取得平衡。

  

## **分布式**

P-D 分离，并不是银弹，它在带来多种好处的同时，也带来了网络上的复杂性。

我们知道网络是比较容易出现问题的，那么如何能保障 P-D 分离的稳定性呢？这基本上和传统分布式服务遇到的问题一致。我们借鉴分布式系统的经验，为 P-D 分离集群引入了多节点 / 多集群，基于服务发现和负载均衡组件，自动化并且人工可控制的进行故障迁移、恢复和回退，以及兼容灰度升级，为用户的服务保驾护航。并且对于 Prefill-Decode 我们引入了不同的配置，配合各自的特性，最大化它们的收益。

### Serverless

我们提供的推理产品，既支持私有部署，也支持共享访问，也即 MaaS 服务（Model as a Service），**用户付费，获得模型的访问能力，不需要关心基础设施资源的分配和运维部署，以及可用性，我们自然提供满足 SLA 要求的服务**。对于 P-D 分离集群来说，我们提供了多种 Prefill-Decode 集群，并且部署了自动弹性策略。随着压力的增大，而自动分配更多资源进行服务。在某个 Prefill-Decode 集群出现问题的时候，请求会自动重试其他同机房的机器。并在一定程度下，可选地可以回退到 Prefill 执行 Decode 请求。最大限度的保障服务的可用性。新启动的机器，除了模型权重之外，不需要持有任何状态即可服务。一个会话，也不需要任何状态，可以直接迁移到另外的 Decode 机器。**这为部署带来了相当大的灵活性**。

### 系统复杂性

P-D 分离之后，系统会变得比较复杂。首先它需要，至少一个 Prefill 节点，一个 Decode 节点。很多流量稀疏场景，一张卡已经足够。此时 P-D 分离并没有带来收益，成本反而还增加了。所以，**我们也需要支持 P-D 分离架构，回退成普通模式**。并且在请求级别的目标输出长度比较短的时候，**应该能自适应的回退到 P-D 融合模式**。

  

P-D 分离之后，网络上的错误会更容易出现，并且因为部署的 Decode 个数比较少，如果他们出现了服务不可用的问题影响会更大。我们在部署了多节点来保障分布式系统的可靠性之外，还部署了多 Cluster，进一步加强稳定性。在发布的时候，**可以按照 Cluster 级别单独灰度升级**。在故障的时候，会自动切换到其他正常的节点 / Cluster 来服务。依赖我们的服务发现组件还可以提供可控性，我们可以在单节点故障的时候，直接降低单节点的权重，或者控制下线，从而不再访问故障节点，降低故障影响范围。

  

Prefill 和 Decode 的特性很不同，所以参数配置上很多都是不同的。例如凑批策略，量化类型，TP 大小，PP 大小，任务超时时间，重试时间，显存申请策略，RDMA 软硬件队列大小，是否可回退执行等。这些需要靠完善的产品机制，在拉起 Prefill-Decode 实例的时候，分别传入不同的参数值。

  

P-D 分离之后，我们需要考虑它的升级过程，不但需要保证总服务可用度，还要保证兼容性。首先如果只有 1 个 P-D 实例，需要保证在升级的时候，起新下老。**并且保证新的 Prefill 访问新的 Decode，这样才能保证协议兼容性**。那这个如何控制呢？我们可以通过在服务发现中注册自己的版本信息，在 Prefill 访问的时候，选择对应的版本来进行访问。

  

### 负载均衡

在 P-D 分离复杂的异构机型集群下，并且 Decode 本身还存在多集群，而且多集群的 TP 大小可能还不一致。此时当前的 Prefill 访问哪一台 Decode，这有很多的策略：

  

- 基于访问后端的总时延：但是不同请求的总时延的差异是很大的，这不是一个好指标。
- 基于后端产出的单轮 Token 的时延：好像有一定的可行性，不过这和当前凑批的大小也有一定的关系，而且这个指标可能存在一定的跳跃性，需要做滑动指数平均。
- **基于后端的剩余显存容量**：如果后端的集群是异构的，那么这个策略会失效。
- 基于后端的吞吐：也就是单位时间内产出的 Token 总数，在离线场景可能是比较适合的。

  

但是不论负载策略是哪个，都要基于服务发现，及时地将不健康的和下线的节点，在负载均衡里面屏蔽掉访问。同时我们也需要可以配置不同的负载衡均衡策略。