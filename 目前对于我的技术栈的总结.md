# leetcode
有了基础的概念，比如hash表、双指针、滑动窗口、字符串、栈、堆、动态规划、链表、二叉树、图论、回溯、二分查找、贪心

很多时候是换个题，就看不懂了，没有很强很快速的题目抽象思维

# Cpp和stl的八股
学了侯捷c++的内容

对于模板、拷贝构造函数、虚函数、多态、继承的概念有了一定的了解，但是对于c++的新特性、移动语义、左值右值什么的还不懂

# CUDA
基础的block、grid、线程的概念有了认识

对event、stream、graph也有了大致的概念

实操方面，研究了llm.c的reduce算子、softmax算子、attention算子

然后我对之前使用的houyi框架的语音模型进行了测试和学习，对于计算图、图引擎有了基础的了解，比如基础的context、node、graph的关系？关系是什么？（todo）

然后在ppl框架中进行重写，对fbank算子和fft算子起码要做到信手拈来吧，（todo）

对于bank conflict的了解，对于padding的原理懂了，但是padding的问题也比较明显，会导致获取元素的时候存在索引问题（我看的例子是，比如n\*16的矩阵，对其列数进行加一列，就会使得在存入的时候，）**todo，哎呀，bank conflict也是模模糊糊的

nsys和ncu的使用，还能说一点东西？也只是一点点
# 大模型部分
## vllm的内容
能说什么呢？

vllm的使用的技术
### paged attention
这个不好进行提问
### flash attention
v1

v2

v3（这个就不说了）
### 投机采样
使用draft model小模型的对输入的内容进行结果的推理估计，

然后把推理估计的结果，拼接成一个batch的形式，提升大模型的decode速度

### prefix cache
如何使用hash 进行cache的id的设计，
#### 扯到mooncake的kv cache pool

### PD分离
#### PD分离可以扯的东西就很多了
prefill阶段和decode阶段的计算密度

大模型的训练、推理的显存占用计算和推理计算密度的计算

#### vllm的pd分离

做的很简单，是用了
### chunked prefills
是vllm现在使用的方法，主要是取决于vllm的特性？高并发的特性。

把prefill的数据二号