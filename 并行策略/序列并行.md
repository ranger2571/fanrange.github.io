序列并行（sequence parallelism, context parallelism）是 3D 并行之后针对长文本场景的在序列维度进行切分的并行方法。

从实现方法上来说，当前最主流有 [Ring-Attention](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2310.01889) 和 [DeepSpeed Ulysess](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2309.14509)，关于这些方法的原理及实现，之前的众多大佬已经论述备至，因此本篇的目标并不在于提出某种新的方法，而在整体梳理这些方法的核心思想、实现细节、优劣势等，仅以此作为方案解读和学习笔记。

## 一、[Ring Attention](https://zhida.zhihu.com/search?content_id=251955815&content_type=Article&match_order=1&q=Ring+Attention&zhida_source=entity) 的原理与实现

### 1.1 [Allgather](https://zhida.zhihu.com/search?content_id=251955815&content_type=Article&match_order=1&q=Allgather&zhida_source=entity) + [ReduceScatter](https://zhida.zhihu.com/search?content_id=251955815&content_type=Article&match_order=1&q=ReduceScatter&zhida_source=entity) 范式

受 TP 的 allreduce 的启发，最初的 SP 方案多采用 allgather+reduce scatter 的实现方式，即计算 attention 的时候就 allgather 到一起，计算完成后再分发到多个设备。采用这种方式的典型方案有：

- [ColossalAI Sequence Parallelism (Colossal-SP)](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2105.13120)
- [MegatronLM Context Parallelism (Megatron-CP)](https://link.zhihu.com/?target=https%3A//docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/context_parallel.html) : 需要说明的是，[Megatron-LM](https://zhida.zhihu.com/search?content_id=251955815&content_type=Article&match_order=1&q=Megatron-LM&zhida_source=entity)序列并行的原理与 [ZeRO-2](https://zhida.zhihu.com/search?content_id=251955815&content_type=Article&match_order=1&q=ZeRO-2&zhida_source=entity)类似，其本质是优化 TP 操作。 由于 AllReduce 操作恰好是 Allgather 和 ReduceScatter 的组合，因此通信成本保持不变。 在 N 个device中，输入和输出张量的大小减少了 1/N。 由于输入/输出张量中的序列维度是分区的，因此被命名为序列并行性。 然而，这种形式的序列并行如果没有张量并行就无法独立使用。