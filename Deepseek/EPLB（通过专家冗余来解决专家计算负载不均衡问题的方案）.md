
本文主要分析EPLB的处理逻辑、设计思路。并帮助大家理解如下问题：

- EPLB是用在训练过程还是推理过程？（都有？）
- 专家动态调整是发生在什么时候？是每轮迭代吗？(似乎是每十分钟)
- 调整过程需要重新加载权重吗？（不需要，只是复制需求高的专家）
- 均衡的策略怎么设计？（这个就不确定了）

## EP计算平衡问题

在 [Mixture-of-Experts](https://zhida.zhihu.com/search?content_id=255014897&content_type=Article&match_order=1&q=Mixture-of-Experts&zhida_source=entity) (MoE) 架构中，不同专家所接收的输入（tokens）数量存在显著差异，这直接导致了专家计算负载的不均衡。

当这些专家被分配到 GPU 上时，负载差异会引发设备间的计算不均衡问题。

具体表现为部分 GPU 的算力被过度占用，而另一些 GPU 的算力则处于闲置状态。

换句话说，热门专家所在的 GPU 会面临算力紧张的情况，而冷门专家所在的 GPU 则会出现算力浪费的现象。

以下是一个简单的示例，用于说明这一问题。假设模型中有四个专家，分别部署在两张 GPU 上。其中，GPU0 上分配的专家热度较高，需要处理 75% 的输入数据，而 GPU1 上的专家热度较低，仅需处理 25% 的数据

### 全局重排序方案

为了解决不平衡问题，一种解决方案是对专家重新排序，还是以上面示例为例，可以根据分配比例重新排序专家，并采用“高低搭配”的策略来平衡负载，如下所示将专家1和专家2进行位置交换，这样计算量变为：GPU0 45%，GPU1 55%。

### 冗余副本方案

另一种更直接的解决方案是冗余专家策略（[Redundant Experts Strategy](https://zhida.zhihu.com/search?content_id=255014897&content_type=Article&match_order=1&q=Redundant+Experts+Strategy&zhida_source=entity)）。其核心思想是在算力闲置的 GPU 上部署热门**专家的副本**，并将部分**输入分流**到副本上，从而实现负载的均衡。

还是上述例子，在GPU1上面创建一个专家1的副本，然后将25%的计算分到副本。这样计算量：GPU0 50%，GPU1 50%。

### 方案优缺点：

- 全局重排方案：能够让流量更加均匀，而且不需要消耗额外的内存，但需要调整全部的专家。
- 冗余副本方案：避免专家全局调整，但需要消耗额外内存空间。

## EPLB
EPLB的设计结合前面两种方案，设计前还需要考虑的几个问题：

1. 怎么才知道哪些专家热度高呢？
2. 对哪些专家创建冗余副本？
3. 冗余副本与原专家之间怎么组合？

- 问题1：在EPLB中并未给出详细介绍。可以通过统计历史数据，然后根据历史数据来预测专家的热度。（**类似于LRU（用于删除不常用的专家）+调用次数（常用专家统计次数）（似乎只用lru，也可以增加统计调用次数的功能）**）
- 问题2：**简单排序法**：最直接的方式是根据热度对专家进行排序，并为热度最高的专家创建副本。**分组排序法**：根据不同场景的需求，可以先对专家进行分组，然后在每组内按热度排序，选取热度最高的专家创建副本。这种方法可以更灵活地适应不同规模和复杂度的模型。
- 问题3：专家并行计算，**不仅要考虑计算、还需要考虑通信**，应当尽量降低通信，避免大流量跨节点通信。

然后，搭建一个动态负载均衡系统。如下所示：

关键要素：

预测器（Predictor）：采集历史数据，根据统计数据预测EP的权重；

平衡器（Balancer）：根据EP权重计算EP的理想分布，获得逻辑到物理EP的映射map；

执行器（Executer）：输入目标EP的部署形态，调整EP在集群中的部署。

执行器是LLM运行的框架（如，Ray/vLLM/SGLang），预测器可设计在框架的调度器里面。系统设计需要考虑：存储多少历史数据，采用什么控制算法，以平衡**内存/算力消耗**与**预测准确度**之间的关系。

## EPLB的设计思路

当前EPLB代码库只包含平衡器的相关工作实现。涉及几个概念：原有专家（logical experts）、专家副本（replications/replica）、实际部署的专家（physical experts），

数量关系：physical experts = logical experts + replica experts

如下所示，physical experts ：6，logical experts ：4，replica experts：2


代码实现的是一种**局部排序+贪心算法**。

### 推理D/P场景下组合策略的区别。

在Prefill阶段（小EP并行）通过分组让原专家和复制专家在一个group中；在Decoding阶段（大EP并行），对全局专家进行排序。
## 问题讨论：

1. 专家动态调整是发生在什么时候？是每轮迭代吗？

取决于预测算法的设计，频率可高可低。但，因为调整是有开销的，一般不会在每轮迭代中进行一次调整。

2. 调整过程需要重新加载权重吗？

需要。如果是小EP，只涉及小EP范围内的设备，如果是大EP调整范围更大。
所以这个调整策略应用在推理上面更合适，在PD分离中P与D的模块可单独的调整，降低了整个系统开销。