[vllm代码快速上手 - 知乎](https://zhuanlan.zhihu.com/p/6462326972)
主要是看了这篇文章

## **1 [LLMEngine](https://zhida.zhihu.com/search?content_id=250314981&content_type=Article&match_order=1&q=LLMEngine&zhida_source=entity)**

  
LLMEngine就是vllm的核心 class，从vllm运行代码一直讲到LLMEngine

###   
**1.1 vllm运行demo**  

```text
from vllm import LLM, SamplingParams
if __name__ == '__main__':
 model_path = "/data/root/LLM/Qwen1.5-14B-Chat"
 model = LLM(model=model_path, tensor_parallel_size=1, trust_remote_code=True, max_model_len=10000, enforce_eager=True, 
 gpu_memory_utilization=0.5, block_size=32)
 sampling_params = SamplingParams(temperature=0, max_tokens=1, prompt_logprobs=20)
 
 prompt = "今天天气怎么样?"
 response = model.generate(prompt, sampling_params, use_tqdm=False)[0]
 print(response, '\n\n', response.outputs)
```

LLM是入口class

###   **1.2 LLM class**  

代码路径——vllm/entrypoints/llm.py

**1.2.1 初始化**  
核心在于LLMEngine的初始化  
  
**1.2.2 执行**  
提供了几种接口做不同的生成，generate，beam_search，chat，encode。  
这些函数核心都是调用LLMEngine做事情，核心代码是self.\_run_engine(use_tqdm=use_tqdm)。

\_run_engine的核心代码就是 self.llm_engine.step()，这个LLMEngine就是vllm的核心类了。