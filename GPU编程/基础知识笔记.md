### 特点
高并发、低延迟、特化的内存架构

CUDA核心算力的计算法  
- 算力（FLOPS）= CUDA核心数 × 加速频率 × 每核心单个周期浮点计算系数  
- A100的算力（FP32单精度）= 6912（6912个CUDA核心） × 1.41（1.41GHz频率） × 2（单周期2个浮点计算） = 19491.84 GFLOPS ≈ 19.5 TFLOPS

### 架构概述

以NVIDIA为例，就是“从0到Fermi“，和”从Fermi到Blackwell“。Fermi架构是现代通用GPU架构的基石，其中许多核心设计思想传承至今，而此后直到作者撰文的2025年最新的Blackwell架构，都可以看做在基础上的一路迭代。

#### 架构内容
SIMT核心（SIMT Core）是GPU的核心计算单元，负责协调和管理大量线程的并行执行，对应NVIDIA 架构中的SM。

SIMT（Single Instruction, Multiple Threads，单指令多线程），是GPU的核心执行模型，其本质是通过统一指令指挥多个线程并行处理不同数据。

多个SIMT核心组成SIMT Core Cluster，对应NVIDIA的GPC，每个Cluster/GPC可以看做是一个可完整运作的mini GPU，而实际的GPU由多个GPC组成，也就是大家常说的“多核”。

在同一个SIMT核心内运行的线程可以通过共享内存（Shared Memory）来进行彼此通信同步，SIMT核心内还包含一级指令和数据缓存，用来减少与低级内存的交互次数从而提高性能。而SIMT Core Cluster之间通过Interconnection Network通信。